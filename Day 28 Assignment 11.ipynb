{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: \n",
    "Create one array of actual values and another array of predicted values. Compare the two sets with the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual=[1,2,1,1,2,2,1,1,2,1,1,2]\n",
    "\n",
    "predicted=[1,2,2,1,2,1,1,1,2,1,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      " [[6 1]\n",
      " [1 4]]\n",
      "Outcome values : \n",
      " 6 1 1 4\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.86      0.86         7\n",
      "           2       0.80      0.80      0.80         5\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.83      0.83      0.83        12\n",
      "weighted avg       0.83      0.83      0.83        12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matrix=confusion_matrix(actual,predicted,labels=[1,2])\n",
    "print('confusion matrix:\\n',matrix)\n",
    "\n",
    "tp, fn, fp, tn =confusion_matrix(actual,predicted,labels=[1,2]).reshape(-1)\n",
    "print('Outcome values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "matrix=classification_report(actual,predicted,labels=[1,2])\n",
    "print('Classification report : \\n',matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Question 2: \n",
    "Find out the recall, precision, F1 score and confusion matrix with picture\n",
    "\n",
    "1 .cat(42,8)    \n",
    "2 .dog(18,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.86      0.86         7\n",
      "           2       0.80      0.80      0.80         5\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.83      0.83      0.83        12\n",
      "weighted avg       0.83      0.83      0.83        12\n",
      "\n",
      "Accuracy -->  0.74\n",
      "Recall -->  0.7\n",
      "Precision -->  0.84\n",
      "f1 score -->  0.7636363636363636\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mat=np.array([[42,8],[18,32]])\n",
    "print('confusion matrix- \\n',matrix)\n",
    "\n",
    "# True positive\n",
    "tp = mat[0, 0]\n",
    "# True negetive\n",
    "tn = mat[1, 1]\n",
    "# False positive\n",
    "fp = mat[0, 1]\n",
    "# False negetive\n",
    "fn = mat[1, 0]\n",
    "\n",
    "#Accuracy Score\n",
    "accuracy=(tp+tn)/(tp+tn+fp+fn)\n",
    "print('Accuracy --> ',accuracy)\n",
    "\n",
    "#Recall\n",
    "recall=(tp/(tp+fn))\n",
    "print('Recall --> ',recall)\n",
    "\n",
    "#Precision\n",
    "precision=(tp/(tp+fp))\n",
    "print('Precision --> ',precision)\n",
    "\n",
    "#f1 score \n",
    "f1_score=((2*(precision*recall))/(precision+recall))\n",
    "print('f1 score --> ',f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
